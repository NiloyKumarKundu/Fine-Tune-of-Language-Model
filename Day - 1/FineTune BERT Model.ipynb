{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm as notebook_tqdm\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad = load_dataset(\"squad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 87599\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': ['5733be284776f41900661182'],\n",
       " 'title': ['University_of_Notre_Dame'],\n",
       " 'context': ['Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'],\n",
       " 'question': ['To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?'],\n",
       " 'answers': [{'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad['train'][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': ['56be4db0acb8001400a502ec'],\n",
       " 'title': ['Super_Bowl_50'],\n",
       " 'context': ['Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.'],\n",
       " 'question': ['Which NFL team represented the AFC at Super Bowl 50?'],\n",
       " 'answers': [{'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'],\n",
       "   'answer_start': [177, 177, 177]}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad['validation'][:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer\n",
    "\n",
    "- For encoding the data which need to provides to my bert model (transformer encoder)\n",
    "- Transformer(encoded data) --> positional encoding --> attention layer --> neural network --> output\n",
    "- High level overview of transformer working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer --> model --> pretrain --> BERT --> question answering, text classification, sentiment analysis, summarization, translation, etc.\n",
    "\n",
    "Transformer --> BERT --> Specific classes (question answering, text classification, sentiment analysis, summarization, translation, etc.)\n",
    "\n",
    "Transformer --> pytorch (AutoModelForQuestionAnswering, AutoModelForCasualLM, etc.)\n",
    "\n",
    "Transformer --> Tensorflow (TFAutoModel) --> Low level authority --> You can add your own layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(\"bert-base-uncased\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForQuestionAnswering(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': ['56be4db0acb8001400a502ec'],\n",
       " 'title': ['Super_Bowl_50'],\n",
       " 'context': ['Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.'],\n",
       " 'question': ['Which NFL team represented the AFC at Super Bowl 50?'],\n",
       " 'answers': [{'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'],\n",
       "   'answer_start': [177, 177, 177]}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad['validation'][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Which NFL team represented the AFC at Super Bowl 50?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = 'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(text, context, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2029,  5088,  2136,  3421,  1996, 10511,  2012,  3565,  4605,\n",
       "          2753,  1029,   102,  3565,  4605,  2753,  2001,  2019,  2137,  2374,\n",
       "          2208,  2000,  5646,  1996,  3410,  1997,  1996,  2120,  2374,  2223,\n",
       "          1006,  5088,  1007,  2005,  1996,  2325,  2161,  1012,  1996,  2137,\n",
       "          2374,  3034,  1006, 10511,  1007,  3410,  7573, 14169,  3249,  1996,\n",
       "          2120,  2374,  3034,  1006, 22309,  1007,  3410,  3792, 12915,  2484,\n",
       "          1516,  2184,  2000,  7796,  2037,  2353,  3565,  4605,  2516,  1012,\n",
       "          1996,  2208,  2001,  2209,  2006,  2337,  1021,  1010,  2355,  1010,\n",
       "          2012, 11902,  1005,  1055,  3346,  1999,  1996,  2624,  3799,  3016,\n",
       "          2181,  2012,  4203, 10254,  1010,  2662,  1012,  2004,  2023,  2001,\n",
       "          1996, 12951,  3565,  4605,  1010,  1996,  2223, 13155,  1996,  1000,\n",
       "          3585,  5315,  1000,  2007,  2536,  2751,  1011, 11773, 11107,  1010,\n",
       "          2004,  2092,  2004,  8184, 28324,  2075,  1996,  4535,  1997, 10324,\n",
       "          2169,  3565,  4605,  2208,  2007,  3142, 16371, 28990,  2015,  1006,\n",
       "          2104,  2029,  1996,  2208,  2052,  2031,  2042,  2124,  2004,  1000,\n",
       "          3565,  4605,  1048,  1000,  1007,  1010,  2061,  2008,  1996,  8154,\n",
       "          2071, 14500,  3444,  1996,  5640, 16371, 28990,  2015,  2753,  1012,\n",
       "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1]])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Attention mask is which work is important. 1 means important word, 0 means not important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move input tensors to the same device as the model\n",
    "input_ids = inputs[\"input_ids\"].to(device)\n",
    "attention_mask = inputs[\"attention_mask\"].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2029,  5088,  2136,  3421,  1996, 10511,  2012,  3565,  4605,\n",
       "          2753,  1029,   102,  3565,  4605,  2753,  2001,  2019,  2137,  2374,\n",
       "          2208,  2000,  5646,  1996,  3410,  1997,  1996,  2120,  2374,  2223,\n",
       "          1006,  5088,  1007,  2005,  1996,  2325,  2161,  1012,  1996,  2137,\n",
       "          2374,  3034,  1006, 10511,  1007,  3410,  7573, 14169,  3249,  1996,\n",
       "          2120,  2374,  3034,  1006, 22309,  1007,  3410,  3792, 12915,  2484,\n",
       "          1516,  2184,  2000,  7796,  2037,  2353,  3565,  4605,  2516,  1012,\n",
       "          1996,  2208,  2001,  2209,  2006,  2337,  1021,  1010,  2355,  1010,\n",
       "          2012, 11902,  1005,  1055,  3346,  1999,  1996,  2624,  3799,  3016,\n",
       "          2181,  2012,  4203, 10254,  1010,  2662,  1012,  2004,  2023,  2001,\n",
       "          1996, 12951,  3565,  4605,  1010,  1996,  2223, 13155,  1996,  1000,\n",
       "          3585,  5315,  1000,  2007,  2536,  2751,  1011, 11773, 11107,  1010,\n",
       "          2004,  2092,  2004,  8184, 28324,  2075,  1996,  4535,  1997, 10324,\n",
       "          2169,  3565,  4605,  2208,  2007,  3142, 16371, 28990,  2015,  1006,\n",
       "          2104,  2029,  1996,  2208,  2052,  2031,  2042,  2124,  2004,  1000,\n",
       "          3565,  4605,  1048,  1000,  1007,  1010,  2061,  2008,  1996,  8154,\n",
       "          2071, 14500,  3444,  1996,  5640, 16371, 28990,  2015,  2753,  1012,\n",
       "           102]], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1]], device='cuda:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[-9.9525e-02, -1.6205e-02, -5.8271e-02, -4.0584e-01, -1.1191e-02,\n",
       "         -1.0651e-01, -8.7459e-02,  3.5844e-01,  3.8691e-01,  3.5075e-01,\n",
       "          1.9071e-01,  1.0301e-01,  1.7453e-01,  4.4841e-01,  4.2113e-01,\n",
       "          2.6179e-01,  1.2617e-01,  2.2724e-01, -1.8773e-01,  8.4850e-02,\n",
       "          1.0451e-01,  8.3353e-02,  5.2257e-01, -2.9884e-01, -3.6994e-02,\n",
       "         -8.8060e-02, -2.9656e-01,  1.7547e-01,  3.6042e-01,  1.1349e-01,\n",
       "         -1.4115e-01,  1.2845e-01,  1.1504e-01,  1.5430e-02, -2.5788e-01,\n",
       "          1.5131e-01,  1.0811e-01, -4.5800e-01, -5.2916e-01, -1.8176e-02,\n",
       "          2.6946e-01,  1.6311e-01, -1.2378e-02,  2.8995e-02,  2.1362e-01,\n",
       "         -2.4795e-01, -2.4248e-01, -9.6852e-02, -5.7364e-02, -4.3557e-01,\n",
       "          8.3975e-02,  3.3610e-01,  2.6692e-01,  9.0950e-02,  1.8509e-02,\n",
       "         -4.8028e-01, -2.4935e-01, -1.1934e-01, -2.4996e-01, -2.2500e-01,\n",
       "         -2.3658e-01, -3.5485e-02, -9.3080e-02,  1.0425e-01,  1.0147e-01,\n",
       "          6.1986e-02,  3.4700e-01, -2.8581e-02, -5.1743e-01, -4.6274e-01,\n",
       "          2.3240e-01,  2.6104e-01,  2.9691e-01,  5.7797e-01,  2.8322e-01,\n",
       "          5.6134e-01,  2.8714e-01, -2.0860e-01, -2.6269e-01, -4.2848e-01,\n",
       "          4.3447e-01,  8.8828e-02, -2.7011e-01, -5.4207e-02,  1.1277e-01,\n",
       "          4.1235e-01, -2.1411e-01, -9.1006e-03, -1.2955e-01, -3.4214e-01,\n",
       "          1.7978e-01,  2.9882e-01, -1.4003e-01, -2.7539e-02, -2.1423e-01,\n",
       "         -4.6451e-01, -4.6481e-01, -2.5262e-01,  4.2685e-01,  4.1605e-01,\n",
       "          1.2495e-01,  2.5083e-01,  2.5213e-01, -5.8148e-02, -4.8876e-01,\n",
       "          4.1592e-03,  1.9890e-01,  2.8678e-01,  1.2666e-01,  1.9287e-01,\n",
       "          2.0813e-01, -7.2739e-02,  2.9222e-02, -2.9227e-01,  1.2990e-01,\n",
       "         -1.0226e-01,  2.8183e-01,  3.8781e-01,  1.6636e-01, -4.8188e-01,\n",
       "         -2.9453e-02,  7.3839e-02, -1.5030e-01,  3.7092e-02, -1.5049e-02,\n",
       "         -1.7414e-01, -2.2567e-01,  2.6710e-01, -1.7343e-02,  5.4030e-02,\n",
       "          2.7160e-02,  3.0665e-01,  4.3254e-02, -1.2673e-01,  1.3486e-01,\n",
       "         -2.0931e-03,  3.8230e-01,  3.3596e-01, -1.0627e-01, -4.6681e-02,\n",
       "         -4.1622e-01,  1.1557e-01, -1.8785e-02,  4.4684e-02,  4.3425e-01,\n",
       "          2.3163e-01,  5.5113e-03, -5.8558e-02, -2.1265e-01,  1.7695e-01,\n",
       "          2.5921e-01,  1.3311e-01,  2.2595e-01,  1.5254e-02, -4.7466e-01,\n",
       "         -4.8102e-01, -2.5391e-01, -1.0223e-01, -1.0231e-01, -1.0942e-01,\n",
       "          1.3725e-02, -1.5807e-01, -1.9546e-02, -2.2435e-01, -4.6048e-01,\n",
       "          2.2426e-01,  3.8855e-01, -2.8484e-05,  1.3313e-01, -4.5250e-01,\n",
       "          1.7594e-01]], device='cuda:0'), end_logits=tensor([[ 0.9637,  0.3824,  0.1824,  0.6251,  0.3256,  0.2387, -0.0265,  0.2797,\n",
       "         -0.1483, -0.1341,  0.3057, -0.1693,  0.1827, -0.0031,  0.0113,  0.3109,\n",
       "          0.3064,  0.5739, -0.3737, -0.2018,  0.5672,  0.3253,  0.2871,  0.0871,\n",
       "          0.3093, -0.0133, -0.0108, -0.3007, -0.4083,  0.1139, -0.1556, -0.2368,\n",
       "          0.0904, -0.3656,  0.0190, -0.2405,  0.4642, -0.3385,  0.1299, -0.7632,\n",
       "         -0.4328,  0.2373, -0.1090, -0.2327,  0.3647,  0.0599,  0.0975, -0.2161,\n",
       "          0.4201,  0.0172, -0.2779, -0.4061, -0.0503,  0.0436, -0.3024, -0.3493,\n",
       "          0.2447, -0.0832, -0.1213,  0.2020,  0.2552,  0.2779, -0.0106,  0.3784,\n",
       "          0.2274,  0.0621, -0.0186, -0.0278,  0.0353, -0.3324,  0.4175,  0.4267,\n",
       "          0.4440,  0.5848,  0.4576,  0.2086,  0.3373, -0.2441, -0.3948, -0.2961,\n",
       "          0.4459,  0.1598,  0.3797,  0.1795, -0.0999,  0.3271,  0.4559,  0.1409,\n",
       "          0.0800,  0.6206,  0.3769,  0.2767,  0.2124,  0.4997,  0.2332,  0.5271,\n",
       "         -0.3232,  0.6747,  0.7288,  0.3358,  0.0750,  0.4206,  0.0457,  0.1873,\n",
       "         -0.3404,  0.4386,  0.5210,  0.4655,  0.2028,  0.4868,  0.7023,  0.5224,\n",
       "          0.8703,  0.3987,  0.5762,  0.9556,  0.6243,  0.6976,  0.5687, -0.3555,\n",
       "          0.9455,  0.7260,  0.5792,  0.2147,  0.0089,  0.2348,  0.0543,  0.0747,\n",
       "          0.0506,  0.1734,  0.1292, -0.0240,  0.2921,  0.4335, -0.3516, -0.2333,\n",
       "         -0.5545, -0.3634, -0.2524,  0.0376,  0.0788, -0.0740, -0.1508,  0.2930,\n",
       "          0.1931, -0.0096,  0.2173,  0.1893,  0.0901,  0.2897, -0.1209,  0.2831,\n",
       "          0.5395,  0.6879, -0.2622, -0.3313, -0.0332,  0.2555,  0.2664,  0.4387,\n",
       "          0.6498,  0.2407,  0.1417, -0.5049,  0.0577, -0.5647, -0.5611, -0.2238,\n",
       "         -0.0233, -0.3341,  0.1857]], device='cuda:0'), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.9525e-02, -1.6205e-02, -5.8271e-02, -4.0584e-01, -1.1191e-02,\n",
       "         -1.0651e-01, -8.7459e-02,  3.5844e-01,  3.8691e-01,  3.5075e-01,\n",
       "          1.9071e-01,  1.0301e-01,  1.7453e-01,  4.4841e-01,  4.2113e-01,\n",
       "          2.6179e-01,  1.2617e-01,  2.2724e-01, -1.8773e-01,  8.4850e-02,\n",
       "          1.0451e-01,  8.3353e-02,  5.2257e-01, -2.9884e-01, -3.6994e-02,\n",
       "         -8.8060e-02, -2.9656e-01,  1.7547e-01,  3.6042e-01,  1.1349e-01,\n",
       "         -1.4115e-01,  1.2845e-01,  1.1504e-01,  1.5430e-02, -2.5788e-01,\n",
       "          1.5131e-01,  1.0811e-01, -4.5800e-01, -5.2916e-01, -1.8176e-02,\n",
       "          2.6946e-01,  1.6311e-01, -1.2378e-02,  2.8995e-02,  2.1362e-01,\n",
       "         -2.4795e-01, -2.4248e-01, -9.6852e-02, -5.7364e-02, -4.3557e-01,\n",
       "          8.3975e-02,  3.3610e-01,  2.6692e-01,  9.0950e-02,  1.8509e-02,\n",
       "         -4.8028e-01, -2.4935e-01, -1.1934e-01, -2.4996e-01, -2.2500e-01,\n",
       "         -2.3658e-01, -3.5485e-02, -9.3080e-02,  1.0425e-01,  1.0147e-01,\n",
       "          6.1986e-02,  3.4700e-01, -2.8581e-02, -5.1743e-01, -4.6274e-01,\n",
       "          2.3240e-01,  2.6104e-01,  2.9691e-01,  5.7797e-01,  2.8322e-01,\n",
       "          5.6134e-01,  2.8714e-01, -2.0860e-01, -2.6269e-01, -4.2848e-01,\n",
       "          4.3447e-01,  8.8828e-02, -2.7011e-01, -5.4207e-02,  1.1277e-01,\n",
       "          4.1235e-01, -2.1411e-01, -9.1006e-03, -1.2955e-01, -3.4214e-01,\n",
       "          1.7978e-01,  2.9882e-01, -1.4003e-01, -2.7539e-02, -2.1423e-01,\n",
       "         -4.6451e-01, -4.6481e-01, -2.5262e-01,  4.2685e-01,  4.1605e-01,\n",
       "          1.2495e-01,  2.5083e-01,  2.5213e-01, -5.8148e-02, -4.8876e-01,\n",
       "          4.1592e-03,  1.9890e-01,  2.8678e-01,  1.2666e-01,  1.9287e-01,\n",
       "          2.0813e-01, -7.2739e-02,  2.9222e-02, -2.9227e-01,  1.2990e-01,\n",
       "         -1.0226e-01,  2.8183e-01,  3.8781e-01,  1.6636e-01, -4.8188e-01,\n",
       "         -2.9453e-02,  7.3839e-02, -1.5030e-01,  3.7092e-02, -1.5049e-02,\n",
       "         -1.7414e-01, -2.2567e-01,  2.6710e-01, -1.7343e-02,  5.4030e-02,\n",
       "          2.7160e-02,  3.0665e-01,  4.3254e-02, -1.2673e-01,  1.3486e-01,\n",
       "         -2.0931e-03,  3.8230e-01,  3.3596e-01, -1.0627e-01, -4.6681e-02,\n",
       "         -4.1622e-01,  1.1557e-01, -1.8785e-02,  4.4684e-02,  4.3425e-01,\n",
       "          2.3163e-01,  5.5113e-03, -5.8558e-02, -2.1265e-01,  1.7695e-01,\n",
       "          2.5921e-01,  1.3311e-01,  2.2595e-01,  1.5254e-02, -4.7466e-01,\n",
       "         -4.8102e-01, -2.5391e-01, -1.0223e-01, -1.0231e-01, -1.0942e-01,\n",
       "          1.3725e-02, -1.5807e-01, -1.9546e-02, -2.2435e-01, -4.6048e-01,\n",
       "          2.2426e-01,  3.8855e-01, -2.8484e-05,  1.3313e-01, -4.5250e-01,\n",
       "          1.7594e-01]], device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.start_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9637,  0.3824,  0.1824,  0.6251,  0.3256,  0.2387, -0.0265,  0.2797,\n",
       "         -0.1483, -0.1341,  0.3057, -0.1693,  0.1827, -0.0031,  0.0113,  0.3109,\n",
       "          0.3064,  0.5739, -0.3737, -0.2018,  0.5672,  0.3253,  0.2871,  0.0871,\n",
       "          0.3093, -0.0133, -0.0108, -0.3007, -0.4083,  0.1139, -0.1556, -0.2368,\n",
       "          0.0904, -0.3656,  0.0190, -0.2405,  0.4642, -0.3385,  0.1299, -0.7632,\n",
       "         -0.4328,  0.2373, -0.1090, -0.2327,  0.3647,  0.0599,  0.0975, -0.2161,\n",
       "          0.4201,  0.0172, -0.2779, -0.4061, -0.0503,  0.0436, -0.3024, -0.3493,\n",
       "          0.2447, -0.0832, -0.1213,  0.2020,  0.2552,  0.2779, -0.0106,  0.3784,\n",
       "          0.2274,  0.0621, -0.0186, -0.0278,  0.0353, -0.3324,  0.4175,  0.4267,\n",
       "          0.4440,  0.5848,  0.4576,  0.2086,  0.3373, -0.2441, -0.3948, -0.2961,\n",
       "          0.4459,  0.1598,  0.3797,  0.1795, -0.0999,  0.3271,  0.4559,  0.1409,\n",
       "          0.0800,  0.6206,  0.3769,  0.2767,  0.2124,  0.4997,  0.2332,  0.5271,\n",
       "         -0.3232,  0.6747,  0.7288,  0.3358,  0.0750,  0.4206,  0.0457,  0.1873,\n",
       "         -0.3404,  0.4386,  0.5210,  0.4655,  0.2028,  0.4868,  0.7023,  0.5224,\n",
       "          0.8703,  0.3987,  0.5762,  0.9556,  0.6243,  0.6976,  0.5687, -0.3555,\n",
       "          0.9455,  0.7260,  0.5792,  0.2147,  0.0089,  0.2348,  0.0543,  0.0747,\n",
       "          0.0506,  0.1734,  0.1292, -0.0240,  0.2921,  0.4335, -0.3516, -0.2333,\n",
       "         -0.5545, -0.3634, -0.2524,  0.0376,  0.0788, -0.0740, -0.1508,  0.2930,\n",
       "          0.1931, -0.0096,  0.2173,  0.1893,  0.0901,  0.2897, -0.1209,  0.2831,\n",
       "          0.5395,  0.6879, -0.2622, -0.3313, -0.0332,  0.2555,  0.2664,  0.4387,\n",
       "          0.6498,  0.2407,  0.1417, -0.5049,  0.0577, -0.5647, -0.5611, -0.2238,\n",
       "         -0.0233, -0.3341,  0.1857]], device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_scores = outputs.start_logits\n",
    "end_scores = outputs.end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = torch.argmax(start_scores)\n",
    "end_index = torch.argmax(end_scores) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(73, device='cuda:0'), tensor(1, device='cuda:0'))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_index, end_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2029,  5088,  2136,  3421,  1996, 10511,  2012,  3565,  4605,\n",
       "          2753,  1029,   102,  3565,  4605,  2753,  2001,  2019,  2137,  2374,\n",
       "          2208,  2000,  5646,  1996,  3410,  1997,  1996,  2120,  2374,  2223,\n",
       "          1006,  5088,  1007,  2005,  1996,  2325,  2161,  1012,  1996,  2137,\n",
       "          2374,  3034,  1006, 10511,  1007,  3410,  7573, 14169,  3249,  1996,\n",
       "          2120,  2374,  3034,  1006, 22309,  1007,  3410,  3792, 12915,  2484,\n",
       "          1516,  2184,  2000,  7796,  2037,  2353,  3565,  4605,  2516,  1012,\n",
       "          1996,  2208,  2001,  2209,  2006,  2337,  1021,  1010,  2355,  1010,\n",
       "          2012, 11902,  1005,  1055,  3346,  1999,  1996,  2624,  3799,  3016,\n",
       "          2181,  2012,  4203, 10254,  1010,  2662,  1012,  2004,  2023,  2001,\n",
       "          1996, 12951,  3565,  4605,  1010,  1996,  2223, 13155,  1996,  1000,\n",
       "          3585,  5315,  1000,  2007,  2536,  2751,  1011, 11773, 11107,  1010,\n",
       "          2004,  2092,  2004,  8184, 28324,  2075,  1996,  4535,  1997, 10324,\n",
       "          2169,  3565,  4605,  2208,  2007,  3142, 16371, 28990,  2015,  1006,\n",
       "          2104,  2029,  1996,  2208,  2052,  2031,  2042,  2124,  2004,  1000,\n",
       "          3565,  4605,  1048,  1000,  1007,  1010,  2061,  2008,  1996,  8154,\n",
       "          2071, 14500,  3444,  1996,  5640, 16371, 28990,  2015,  2753,  1012,\n",
       "           102]], device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_tokens = input_ids[0][start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(answer_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LLM model --> Inferencing --> Question Answering\n",
    "- Inferencing --> load the pretraining model and test your model over the test data.\n",
    "- Inferencing is the prediction on top of the data which is not seen by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process the data and then finetune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_features(examples):\n",
    "    # Tokenize our examples with truncation and padding, but keep the overflows using a stride.\n",
    "    # This results in one example possible giving several features when a context is long, \n",
    "    # each of those features having a context that overlaps a bit the context of the previous feature.\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples['question'],\n",
    "        examples['context'],\n",
    "        truncation='only_second', # truncate context, not the question\n",
    "        max_length=384,\n",
    "        stride=128,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding='max_length',\n",
    "    )\n",
    "    \n",
    "    # Since one example might give us several features if it has a long context, we need a map from a feature to its corresponding example.\n",
    "    # This key will help us map the token's position to its position in the list of sentence.\n",
    "    sample_mapping = tokenized_examples.pop('overflow_to_sample_mapping')\n",
    "    \n",
    "    # The offset mappings will give us a map from token to character position in the original context. \n",
    "    # This will help us compute the start_positions and end_positions.\n",
    "    offset_mapping = tokenized_examples.pop('offset_mapping')\n",
    "    \n",
    "    # Let's label those examples!\n",
    "    tokenized_examples['start_positions'] = []\n",
    "    tokenized_examples['end_positions'] = []\n",
    "    \n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        # We will label impossible answers with the index of the CLS token.\n",
    "        input_ids = tokenized_examples['input_ids'][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "        \n",
    "        # Grab the sequence corresponding to that example (to know what is the context and what is the question)\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "        \n",
    "        # One example can give several spans, this is the index of the example containing this span of texts\n",
    "        sample_index = sample_mapping[i]\n",
    "        answers = examples['answers'][sample_index]\n",
    "        # If no answers are given, set the cls_index as answer.\n",
    "        \n",
    "        if len(answers['answer_start']) == 0:\n",
    "            tokenized_examples['start_positions'].append(cls_index)\n",
    "            tokenized_examples['end_positions'].append(cls_index)\n",
    "        else:\n",
    "            # Start/end character index of the answer in the text.\n",
    "            start_char = answers['answer_start'][0]\n",
    "            end_char = start_char + len(answers['text'][0])\n",
    "            \n",
    "            # Start token index of the current span in the text.\n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != 1:\n",
    "                token_start_index += 1\n",
    "                \n",
    "            # End token index of the current span in the text.\n",
    "            token_end_index = len(input_ids) - 1\n",
    "            while sequence_ids[token_end_index] != 1:\n",
    "                token_end_index -= 1\n",
    "                \n",
    "            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS)\n",
    "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "                tokenized_examples['start_positions'].append(cls_index)\n",
    "                tokenized_examples['end_positions'].append(cls_index)\n",
    "            else:\n",
    "                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n",
    "                # Note: we could go after the last offset if the answer is the last word (edge case).\n",
    "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                    token_start_index += 1\n",
    "                tokenized_examples['start_positions'].append(token_start_index - 1)\n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                tokenized_examples['end_positions'].append(token_end_index + 1)\n",
    "                \n",
    "    return tokenized_examples\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = squad['validation'][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 2029, 5088, 2136, 3421, 1996, 10511, 2012, 3565, 4605, 2753, 1029, 102, 3565, 4605, 2753, 2001, 2019, 2137, 2374, 2208, 2000, 5646, 1996, 3410, 1997, 1996, 2120, 2374, 2223, 1006, 5088, 1007, 2005, 1996, 2325, 2161, 1012, 1996, 2137, 2374, 3034, 1006, 10511, 1007, 3410, 7573, 14169, 3249, 1996, 2120, 2374, 3034, 1006, 22309, 1007, 3410, 3792, 12915, 2484, 1516, 2184, 2000, 7796, 2037, 2353, 3565, 4605, 2516, 1012, 1996, 2208, 2001, 2209, 2006, 2337, 1021, 1010, 2355, 1010, 2012, 11902, 1005, 1055, 3346, 1999, 1996, 2624, 3799, 3016, 2181, 2012, 4203, 10254, 1010, 2662, 1012, 2004, 2023, 2001, 1996, 12951, 3565, 4605, 1010, 1996, 2223, 13155, 1996, 1000, 3585, 5315, 1000, 2007, 2536, 2751, 1011, 11773, 11107, 1010, 2004, 2092, 2004, 8184, 28324, 2075, 1996, 4535, 1997, 10324, 2169, 3565, 4605, 2208, 2007, 3142, 16371, 28990, 2015, 1006, 2104, 2029, 1996, 2208, 2052, 2031, 2042, 2124, 2004, 1000, 3565, 4605, 1048, 1000, 1007, 1010, 2061, 2008, 1996, 8154, 2071, 14500, 3444, 1996, 5640, 16371, 28990, 2015, 2753, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'start_positions': [46], 'end_positions': [47]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_train_features(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = squad.map(prepare_train_features, batched=True, remove_columns=squad['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "    num_rows: 88524\n",
       "})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "    num_rows: 10784\n",
       "})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['validation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning the BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir='finetune-BERT-squad',\n",
    "    eval_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "data_collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data Collator --> It take care the optimization of the training and provide the data in form of batches.\n",
    "- data_collator is used to create batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets['train'].select(range(2000)),\n",
    "    eval_dataset=tokenized_datasets['validation'].select(range(2000)),\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ad1829248aa4b74be0f46d9566b0242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad25df68fc947968b3db6086976558f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.34498929977417, 'eval_runtime': 25.0612, 'eval_samples_per_second': 79.805, 'eval_steps_per_second': 9.976, 'epoch': 1.0}\n",
      "{'loss': 2.5716, 'grad_norm': 37.80916976928711, 'learning_rate': 1.2e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1f4b4c3de5d48a694e00ccdbd6ac119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.9134577512741089, 'eval_runtime': 25.0092, 'eval_samples_per_second': 79.971, 'eval_steps_per_second': 9.996, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc6c70dd90ce4a3397a7f0ec978cc71a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.9042402505874634, 'eval_runtime': 25.4438, 'eval_samples_per_second': 78.605, 'eval_steps_per_second': 9.826, 'epoch': 3.0}\n",
      "{'loss': 0.8364, 'grad_norm': 16.585693359375, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b537ed8712644adbe2f65aa97201b7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.9276578426361084, 'eval_runtime': 25.3952, 'eval_samples_per_second': 78.755, 'eval_steps_per_second': 9.844, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27b1c661a3a24bc7ae81cec0f56d907e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.993401050567627, 'eval_runtime': 25.2327, 'eval_samples_per_second': 79.262, 'eval_steps_per_second': 9.908, 'epoch': 5.0}\n",
      "{'train_runtime': 570.7317, 'train_samples_per_second': 17.521, 'train_steps_per_second': 2.19, 'train_loss': 1.4610540405273438, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1250, training_loss=1.4610540405273438, metrics={'train_runtime': 570.7317, 'train_samples_per_second': 17.521, 'train_steps_per_second': 2.19, 'total_flos': 1959725675520000.0, 'train_loss': 1.4610540405273438, 'epoch': 5.0})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 2029, 5088, 2136, 3421, 1996, 10511, 2012, 3565, 4605, 2753, 1029, 102, 3565, 4605, 2753, 2001, 2019, 2137, 2374, 2208, 2000, 5646, 1996, 3410, 1997, 1996, 2120, 2374, 2223, 1006, 5088, 1007, 2005, 1996, 2325, 2161, 1012, 1996, 2137, 2374, 3034, 1006, 10511, 1007, 3410, 7573, 14169, 3249, 1996, 2120, 2374, 3034, 1006, 22309, 1007, 3410, 3792, 12915, 2484, 1516, 2184, 2000, 7796, 2037, 2353, 3565, 4605, 2516, 1012, 1996, 2208, 2001, 2209, 2006, 2337, 1021, 1010, 2355, 1010, 2012, 11902, 1005, 1055, 3346, 1999, 1996, 2624, 3799, 3016, 2181, 2012, 4203, 10254, 1010, 2662, 1012, 2004, 2023, 2001, 1996, 12951, 3565, 4605, 1010, 1996, 2223, 13155, 1996, 1000, 3585, 5315, 1000, 2007, 2536, 2751, 1011, 11773, 11107, 1010, 2004, 2092, 2004, 8184, 28324, 2075, 1996, 4535, 1997, 10324, 2169, 3565, 4605, 2208, 2007, 3142, 16371, 28990, 2015, 1006, 2104, 2029, 1996, 2208, 2052, 2031, 2042, 2124, 2004, 1000, 3565, 4605, 1048, 1000, 1007, 1010, 2061, 2008, 1996, 8154, 2071, 14500, 3444, 1996, 5640, 16371, 28990, 2015, 2753, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'start_positions': [46], 'end_positions': [47]}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
